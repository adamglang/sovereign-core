# Sovereign Core Configuration
# Use environment variables for sensitive data like API keys

# Wake-word detection settings
wake_word:
  # Picovoice Porcupine access key (set via PORCUPINE_ACCESS_KEY env var)
  access_key: ${PORCUPINE_ACCESS_KEY}
  # Wake word keywords to listen for (not used when keyword_path is set)
  keywords: ["hey sovereign"]
  # Path to custom wake word .ppn file (optional - uses built-in keywords if not provided)
  keyword_path: "sovereign_core/assets/wake_words/hey-sovereign_en_windows_v4_0_0.ppn"
  # Sensitivity (0.0 to 1.0) - higher means more sensitive but more false positives
  sensitivity: 0.5

# Audio input settings
audio:
  # Sample rate in Hz
  sample_rate: 16000
  # Number of audio channels
  channels: 1
  # Frame duration in milliseconds
  frame_duration_ms: 30
  # Input device index (null = default device)
  device_index: null

# Turn-taking and voice activity detection settings
turn_taking:
  # VAD aggressiveness (0-3): higher = more aggressive filtering, fewer false positives
  vad_aggressiveness: 2
  # Minimum speech duration in milliseconds to trigger recording
  min_speech_duration_ms: 300
  # Duration of silence in milliseconds to end recording
  end_silence_duration_ms: 700
  # Grace period in milliseconds after speech ends before processing
  post_speech_grace_ms: 500
  # Maximum recording duration in seconds (safety limit)
  max_recording_duration_s: 15
  # VAD frame duration in milliseconds (must be 10, 20, or 30)
  vad_frame_duration_ms: 30

# Speech-to-Text settings
stt:
  # faster-whisper model size: tiny, base, small, medium, large-v2, large-v3
  model_size: "base"
  # Device: "cuda" for GPU, "cpu" for CPU
  device: "cpu"
  # Compute type: "float16" for GPU, "int8" for CPU
  compute_type: "int8"
  # Model download/cache directory
  model_dir: "./models/whisper"

# LLM settings
llm:
  # Provider: "openai" (more providers can be added later)
  # Changing this is the ONLY change needed to swap LLM providers
  provider: "openai"
  # Model name (gpt-4o-mini for POC cost efficiency)
  model: "gpt-4o-mini"
  # Temperature for response generation (0.0 = deterministic, 1.0 = creative)
  temperature: 0.7
  # Max tokens in response
  max_tokens: 1000

# Text-to-Speech settings
tts:
  # Piper voice model name (without .onnx extension)
  # Options: en_US-lessac-medium, en_US-libritts-high, en_US-amy-medium
  voice_model: "en_US-amy-medium"
  
  # Speaker ID for multi-speaker models (null = default speaker)
  speaker_id: null
  
  # GPU acceleration (requires onnxruntime-gpu and CUDA)
  use_cuda: true

# Inter-process communication settings
ipc:
  # SQLite database path for IPC
  database_path: "./sovereign.db"
  # Connection timeout in seconds
  timeout: 30

# Routing settings
router:
  # Keywords that indicate action requests vs conversation
  action_keywords:
    - "execute"
    - "run"
    - "start"
    - "stop"
    - "open"
    - "close"
    - "launch"

# Conversation history settings
conversation:
  # Maximum number of messages to store in conversation history
  max_history_messages: 10
  # Number of messages to pass as context to LLM
  context_messages: 10
  # Time in seconds to continue listening for follow-up input without requiring wake word
  # Set to 0 to always require wake word
  follow_up_timeout_seconds: 10.0

# Logging settings
logging:
  # Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: "INFO"
  # Log file path
  file: "./logs/sovereign.log"
  # Console output enabled
  console: true
  # Maximum log file size in bytes (default: 10MB)
  max_bytes: 10485760
  # Number of backup log files to keep
  backup_count: 5
  # Log level for third-party libraries (prevents bloat from verbose logging)
  third_party_level: "WARNING"
  # Third-party loggers to filter (set to third_party_level instead of root level)
  third_party_loggers:
    - "pvporcupine"
    - "pyaudio"
    - "faster_whisper"
    - "openai"
    - "httpx"
    - "httpcore"
    - "urllib3"
    - "sounddevice"